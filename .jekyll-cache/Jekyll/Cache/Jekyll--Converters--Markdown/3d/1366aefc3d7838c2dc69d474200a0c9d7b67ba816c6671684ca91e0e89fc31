I"ğ<blockquote>
  <p>(https://arxiv.org/abs/1408.5882)[https://arxiv.org/abs/1408.5882]{:target=â€_blankâ€}</p>
</blockquote>

<h1 id="abstract">Abstract</h1>
<p>pretraind word vectorì™€ CNNì„ sentence classification taskì— ì ìš©í•˜ì—¬ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ìŒ</p>

<h1 id="1-introduction">1 Introduction</h1>
<p>ì´ë²ˆ ë…¼ë¬¸ì—ì„œëŠ”, unsupervised neural language modelì„ í†µí•´ í•™ìŠµí•œ word vectorë¥¼ ì´ìš©í•˜ì—¬ cnnì„ í•™ìŠµí•œë‹¤.<br />
word vectorëŠ” google news ì²œì–µ ë‹¨ì–´ë¡œ í•™ìŠµë˜ì—ˆë‹¤. (<a href="https://code.google.com/p/word2vec">https://code.google.com/p/word2vec</a>)<br />
ë¨¼ì € word vectorëŠ” staticí•˜ê²Œ ë†”ë‘ê³ , ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµì„ í•˜ì˜€ë‹¤.<br />
ê°„ë‹¨í•œ íŠœë‹ì„ í†µí•´ì„œ ë§ì€ benchmarkì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì—ˆë‹¤.</p>

<h1 id="2-model">2 Model</h1>
<p><img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/figure_1.png" alt="figure_1.png" /></p>

<p>ëª¨ë¸ ì•„í‚¤í…ì³ëŠ” Collobertì˜ CNN ì•„í‚¤í…ì³ì—ì„œ ì¡°ê¸ˆ ë³€í˜•í•œ ê²ƒì´ë‹¤.<br />
<img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/equation_1.png" alt="equation_1.png" /><br />
x_iëŠ” ë¬¸ì¥ì—ì„œ ië²ˆì§¸ ë‹¨ì–´ì˜ word vectorì´ë‹¤.<br />
<img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/equation_2.png" alt="equation_2.png" /><br />
ê¸¸ì´ê°€ nì¸ ë¬¸ì¥ì€ 1ë¶€í„° nê¹Œì§€ì˜ word vectorì˜ í•©(concatenation)ìœ¼ë¡œ í‘œí˜„ëœë‹¤.<br />
<img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/equation_3.png" alt="equation_3.png" /></p>

<p>CNNì—ëŠ” ìƒˆë¡œìš´ featureë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” filter wê°€ ìˆê³ , hê°œì˜ ë‹¨ì–´ì— ëŒ€í•œ windowì´ë‹¤.<br />
<img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/equation_4.png" alt="equation_4.png" /></p>

<p>ì˜ˆë¥¼ ë“¤ì–´, c_iëŠ” ìœˆë„ìš° í¬ê¸° hì— ëŒ€í•œ x_i:i+h-1ì˜ featureì´ë‹¤.<br />
bëŠ” bias, fëŠ” tanhê°™ì€ non linear functionì´ë‹¤.<br />
<img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/equation_5.png" alt="equation_5.png" /></p>

<p>ì´ filterë¥¼ ì´ìš©í•´ ë¬¸ì¥ì˜ feature map cë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤.</p>

<p>ì¶”ì¶œí•œ feature mapì—ëŠ” max-over-time pooling operationì„ ì ìš©í•œë‹¤. ì´ëŠ” ê°€ì¥ ì¤‘ìš”í•œ featureë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•¨ì´ë‹¤.</p>

<p>ë˜í•œ ì—¬ëŸ¬ê°œì˜ filterë¥¼ ì´ìš©í•´, ì—¬ëŸ¬ê°œì˜ featureë¥¼ ì¶”ì¶œí•˜ê³ , fully connected softmax layerì— ì „ë‹¬í•˜ì—¬ probability distributionì„ êµ¬í•œë‹¤.</p>

<p>ëª¨ë¸ì˜ ë³€í˜• ì¤‘ í•˜ë‚˜ë¡œ, word vectorì— ëŒ€í•´ 2ê°œì˜ channelì„ ì ìš©í•´ë³´ì•˜ë‹¤.</p>

<p>ì²«ë²ˆì§¸ëŠ” pretrained word vectorë¥¼ staticí•˜ê²Œ ë†”ë‘ëŠ” ê²ƒì´ê³ , ë‘ë²ˆì§¸ëŠ” pretrained word vectorì— fine tuningì„ í•˜ëŠ” ê²ƒì´ë‹¤.</p>

<p>ê° filterëŠ” 2ê°œì˜ channelì— ëŒ€í•´ ì ìš©ì´ ë˜ê³ , feature map cë¡œ í•©ì³ì§„ë‹¤.</p>

<h2 id="21-regularization">2.1 Regularization</h2>

<p>regularizationì„ ìœ„í•´ l2 normsë¥¼ ì´ìš©í•œ dropoutì„ ì ìš©í•œë‹¤.<br />
<img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/equation_6.png" alt="equation_6.png" /></p>

<p>mì˜ filterì—ì„œ ì¶”ì¶œí•œ zì— ëŒ€í•´<br />
<img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/equation_7.png" alt="equation_7.png" /></p>

<p>dropoutì„ ì ìš©í•œ ìˆ˜ì‹ì´ë‹¤. rì€ masking vectorì´ë©°, í™•ë¥  pë¥¼ ì´ìš©í•œ random ë³€ìˆ˜ì´ë‹¤.</p>

<p>train ë‹¨ê³„ì—ì„œëŠ” unmasked unitì— ëŒ€í•´ì„œë§Œ í•™ìŠµì„ í•œë‹¤.<br />
<img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/equation_8.png" alt="equation_8.png" /></p>

<p>test ë‹¨ê³„ì—ì„œëŠ” í•™ìŠµëœ weight vectorì— ëŒ€í•´ pë§Œí¼ scaleí•˜ì—¬ ì‚¬ìš©í•œë‹¤.</p>

<p>ì¶”ê°€ì ìœ¼ë¡œ l2 normsë¥¼ ì ìš©í•˜ì—¬, l2 normì„ ì ìš©í•œ wê°€ íŠ¹ì • constraint ê°’ë³´ë‹¤ í´ë•Œë§Œ ì ìš©í•˜ì˜€ë‹¤.</p>

<h1 id="3-datasets-and-experimental-setup">3 Datasets and Experimental Setup</h1>

<p>ë‹¤ì–‘í•œ benchmarkì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤.</p>

<p><img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/table_1.png" alt="table_1.png" /></p>

<h2 id="31-hyperparameters-and-training">3.1 Hyperparameters and Training</h2>

<p>ëª¨ë“  ë°ì´í„°ì…‹ì— ê³µí†µì ìœ¼ë¡œ ì ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°</p>

<ul>
  <li>relu</li>
  <li>filter window size(h) : 3, 4, 5</li>
  <li>100 feature map</li>
  <li>dropout rate(p) : 0.5</li>
  <li>l2 constraint(s) : 3</li>
  <li>mini batch size : 50</li>
</ul>

<p>devì…‹ì— ëŒ€í•œ early stoppingì€ ì ìš©í•˜ì§€ ì•Šì•˜ê³ , devì…‹ì´ ì—†ëŠ” ê²½ìš°ëŠ” training dataì—ì„œ 10%ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ì˜€ë‹¤.<br />
shuffled mini batchì— ëŒ€í•´ adadeltaë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµí•˜ì˜€ë‹¤.</p>

<h2 id="32-pre-trained-word-vectors">3.2 Pre-trained Word Vectors</h2>

<p>pretrained word vectorë¡œ word2vecì„ ì‚¬ìš©í•˜ì˜€ë‹¤.</p>

<p>êµ¬ê¸€ ë‰´ìŠ¤ ì¤‘ ì²œì–µê°œì˜ ë‹¨ì–´ë¡œ í•™ìŠµì´ ë˜ì—ˆê³ , 300 ì°¨ì›ì´ë©° cbow ë°©ì‹ìœ¼ë¡œ í•™ìŠµë˜ì—ˆë‹¤.</p>

<p>pretrained wordì— ì—†ëŠ” ë‹¨ì–´ë¥¼ ëœë¤í•˜ê²Œ ì´ˆê¸°í™”í•˜ì˜€ë‹¤.</p>

<h2 id="33-model-variations">3.3 Model Variations</h2>

<ul>
  <li>CNN-rand : ëª¨ë“  ë‹¨ì–´ëŠ” ëœë¤í•˜ê²Œ ì´ˆê¸°í™”í•˜ì˜€ë‹¤.</li>
  <li>CNN-static : word2vecì„ ì´ìš©í•˜ì˜€ê³ , word vectorëŠ” staticí•˜ê²Œ ìœ ì§€ë˜ê³ , ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµí•˜ì˜€ë‹¤.</li>
  <li>CNN-non-static : word2vecì„ ì´ìš©í•˜ì˜€ê³ , word vectorëŠ” fine tuningë˜ì—ˆë‹¤.</li>
  <li>CNN-multichannel : CNN-staticê³¼ CNN-non-staticì„ í•©ì¹œ ëª¨ë¸ì´ë‹¤.</li>
</ul>

<h1 id="4-results-and-discussion">4 Results and Discussion</h1>

<p><img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/table_2.png" alt="table_2.png" /></p>

<p>CNN-randëŠ” ì¢‹ì§€ ì•Šì•˜ì§€ë§Œ, pretrained vectorë¥¼ ì´ìš©í•œ ë°©ë²•ì€ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.</p>

<p>ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ pretrained vectorë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì„±ëŠ¥ì´ ì¢‹ìœ¼ë©°, ë³´í¸ì ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆë‹¤.</p>

<h2 id="41-multichannel-vs-single-channel-models">4.1 Multichannel vs. Single Channel Models</h2>

<p>multichannelì´ single channel ë³´ë‹¤ ë” ì¢‹ì„ê±°ë¼ê³  ê¸°ëŒ€í–ˆì§€ë§Œ, single channelì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. íŠ¹íˆ ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ single channelì´ ë” ì¢‹ì•˜ë‹¤.</p>

<p>í•˜ì§€ë§Œ multichannelì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ taskë„ ìˆìœ¼ë©°, fine tuning ê³¼ì •ì„ ì •ê·œí™”í•˜ì—¬ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤.</p>

<h2 id="42-static-vs-non-static-representations">4.2 Static vs. Non-static Representations</h2>

<p><img src="/assets/img/user/paper/Convolutional_neural_networks_for_sentence_classification/table_3.png" alt="table_3.png" /></p>

<p>non-static channelì„ í†µí•´ íŠ¹ì • taskì— ë” specificí•˜ê²Œ fine tuning í•  ìˆ˜ ìˆë‹¤.</p>

<p>ì˜ˆë¥¼ ë“¤ì–´, word2vecì—ì„œ badëŠ” goodì´ë‘ ê°€ê¹ì§€ë§Œ, SST-2ì—ì„œëŠ” goodì´ë‘ ê°€ê¹ì§€ ì•Šë‹¤.</p>

<p>pretrained wordì— í¬í•¨ë˜ì§€ ì•Šì•„ ëœë¤í•˜ê²Œ ì´ˆê¸°í™”ëœ ë‹¨ì–´ë“¤ë„ fine tuningì„ í†µí•´ ë”ìš± ì˜ë¯¸ìˆëŠ” í‘œí˜„ìœ¼ë¡œ í•™ìŠµì´ ë˜ì—ˆë‹¤.</p>

<p>ëŠë‚Œí‘œëŠ” ê³¼ì¥ëœ í‘œí˜„(effusive)ê³¼ ì—°ê´€ì´ ìˆê³ í•˜ê³ , ì‰¼í‘œëŠ” ì—°ê²°(conjunctive)ì˜ ì˜ë¯¸ê°€ ìˆë‹¤.</p>

<h2 id="43-further-observations">4.3 Further Observations</h2>

<ul>
  <li>ë™ì¼í•œ ì•„í‚¤í…ì³ì¸ Max-TDNNê³¼ ë¹„êµí•˜ì—¬ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. ë” ë§ì€ filterì™€ feature mapì¸ ê²ƒìœ¼ë¡œ ì¶”ì •í•œë‹¤.</li>
  <li>dropoutì€ ì¢‹ì€ regularizerë¼ëŠ” ê²ƒì„ ì¦ëª…í–ˆë‹¤. 2~4%ì˜ ì„±ëŠ¥í–¥ìƒì„ ë³´ì˜€ë‹¤.</li>
  <li>pretrained wordì— í¬í•¨ë˜ì§€ ì•Šì€ ë‹¨ì–´ì— ëŒ€í•´ ëœë¤í•˜ê²Œ ì´ˆê¸°í™”í• ë•Œ, pretrained vectorì™€ ë™ì¼í•œ ë¶„í¬ë¡œ ì´ˆê¸°í™”í•˜ë©´ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆë‹¤.</li>
  <li>Collobertê°€ í•™ìŠµí•œ pretrained word vectorì— ëŒ€í•´ ì‹¤í—˜ì„ í•´ë³´ì•˜ëŠ”ë°, word2vecì´ ë” ì¢‹ì•˜ë‹¤. ì•„í‚¤í…ì²˜ ë¬¸ì œì¸ì§€ ì²œì–µ ë‹¨ì–´ì˜ êµ¬ê¸€ ë°ì´í„°ì…‹ ì˜í–¥ì¸ì§€ ëª¨ë¥´ê² ë‹¤.</li>
  <li>AdadeltaëŠ” Adagradì™€ ë¹„ìŠ·í•œ ê²°ê³¼ë¥¼ ë³´ì˜€ìœ¼ë‚˜, ë” ë¹¨ë¦¬ í•™ìŠµì´ ì§„í–‰ë˜ì—ˆë‹¤.</li>
</ul>

<h1 id="5-conclusion">5 Conclusion</h1>

<p>NLPì—ì„œ word vectorë¥¼ pretrainingí•˜ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”í•œ ìš”ì†Œì´ë‹¤.</p>
:ET