<!DOCTYPE html><html lang="en" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="theme" content="Chirpy v2.6.2"><meta name="generator" content="Jekyll v4.1.1" /><meta property="og:title" content="BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델" /><meta name="author" content="choi" /><meta property="og:locale" content="en_US" /><meta name="description" content="Config 설정" /><meta property="og:description" content="Config 설정" /><link rel="canonical" href="http://localhost:4000/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_03/" /><meta property="og:url" content="http://localhost:4000/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_03/" /><meta property="og:site_name" content="개발자" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-01-11T00:11:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@choi" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"choi"},"@type":"BlogPosting","description":"Config 설정","headline":"BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델","dateModified":"2021-01-11T00:11:00+09:00","datePublished":"2021-01-11T00:11:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_03/"},"url":"http://localhost:4000/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_03/","@context":"https://schema.org"}</script><title>BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델 | 개발자</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="preload" href="/assets/css/post.css" as="style"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="/assets/js/post.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">개발자</a></div><div class="site-subtitle font-italic">기록 안하면 까먹는다.</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/bhchoi" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['shinejk.qoo','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Jan 11, 2021, 12:11 AM +0900" > Jan 11 <i class="unloaded">2021-01-11T00:11:00+09:00</i> </span> by <span class="author"> choi </span></div></div><div class="post-content"><h2 id="config-설정">Config 설정</h2><p>학습에 필요한 각종 값과 하이퍼파라미터입니다.<br /> argparse를 이용해 인자로 받을 수도 있으나, yaml로 정의하여 불러오도록 하겠습니다.</p><div class="language-yaml highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="na">task</span><span class="pi">:</span> <span class="s">korean_spacing_20210101</span>
<span class="na">log_path</span><span class="pi">:</span> <span class="s">logs</span>
<span class="na">bert_model</span><span class="pi">:</span> <span class="s">monologg/kobert</span>
<span class="na">train_data_path</span><span class="pi">:</span> <span class="s">data/nikl_newspaper/train.txt</span>
<span class="na">val_data_path</span><span class="pi">:</span> <span class="s">data/nikl_newspaper/val.txt</span>
<span class="na">test_data_path</span><span class="pi">:</span> <span class="s">data/nikl_newspaper/test.txt</span>
<span class="na">max_len</span><span class="pi">:</span> <span class="m">128</span>
<span class="na">train_batch_size</span><span class="pi">:</span> <span class="m">128</span>
<span class="na">eval_batch_size</span><span class="pi">:</span> <span class="m">128</span>
<span class="na">dropout_rate</span><span class="pi">:</span> <span class="m">0.1</span>
<span class="na">gpus</span><span class="pi">:</span> <span class="m">8</span>
<span class="na">distributed_backend</span><span class="pi">:</span> <span class="s">ddp</span>
</pre></table></code></div></div><p> </p><h2 id="모델-생성">모델 생성</h2><p>PyTorch Lightning을 이용해 모델을 생성해보겠습니다.<br /> PyTorch Lightning은 tensorflow의 keras처럼, 좀 더 쉽게 pytorch를 사용할 수 있는 라이브러리입니다.<br /> <a href="https://github.com/PyTorchLightning/pytorch-lightning">PyTorchLightning/pytorch-lightning</a></p><p>먼저, pytorch_lightning을 상속받아 클래스를 정의하고, 필요한 function들을 작성해줍니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="n">pl</span>

<span class="k">class</span> <span class="nc">SpacingBertModel</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
</pre></table></code></div></div><p> </p><p>dataset과 학습에 필요한 config를 넘겨받습니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">SpacingBertModel</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">CorpusDataset</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
</pre></table></code></div></div><p> </p><p>dataloader를 생성합니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dataset</span><span class="p">[</span><span class="s">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">train_batch_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dataset</span><span class="p">[</span><span class="s">"val"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">eval_batch_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dataset</span><span class="p">[</span><span class="s">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">eval_batch_size</span><span class="p">)</span>
</pre></table></code></div></div><p> </p><p>모델을 정의하고 forward를 구현합니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">SpacingBertModel</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">CorpusDataset</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">slot_labels_type</span> <span class="o">=</span> <span class="p">[</span><span class="s">"UNK"</span><span class="p">,</span> <span class="s">"PAD"</span><span class="p">,</span> <span class="s">"B"</span><span class="p">,</span> <span class="s">"I"</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert_config</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">bert_model</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span>            <span class="n">slot_labels_type</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">bert_model</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">bert_config</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">bert_config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">slot_labels_type</span><span class="p">)</span>
        <span class="p">)</span>
		
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>
</pre></table></code></div></div><p> </p><p>training을 수행한 결과를 처리하는 부분을 작성합니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_nb</span><span class="p">):</span>

    <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">slot_labels</span> <span class="o">=</span> <span class="n">batch</span>
		
    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_calculate_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span><span class="p">)</span>
    <span class="n">tensorboard_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s">"train_loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="s">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s">"log"</span><span class="p">:</span> <span class="n">tensorboard_logs</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">_calculate_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">active_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">slot_labels_type</span><span class="p">))</span>
    <span class="n">active_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">active_logits</span><span class="p">,</span> <span class="n">active_labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>

<span class="k">def</span> <span class="nf">_f1_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="n">f1_score</span><span class="p">(</span><span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span>
    <span class="p">)</span>
</pre></table></code></div></div><p> </p><p>매 epoch마다 validation을 수행합니다.<br /> validation이 끝날 때마다 무언가를 하고 싶다면 validation_epoch_end()에 추가하면 됩니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_nb</span><span class="p">):</span>
    <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">slot_labels</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_calculate_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span><span class="p">)</span>
    <span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_convert_ids_to_labels</span><span class="p">(</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span>
    <span class="p">)</span>

    <span class="n">val_f1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_f1_score</span><span class="p">(</span><span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s">"val_loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s">"val_f1"</span><span class="p">:</span> <span class="n">val_f1</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]).</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">val_f1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s">"val_f1"</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]).</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">tensorboard_log</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"val_loss"</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span>
        <span class="s">"val_f1"</span><span class="p">:</span> <span class="n">val_f1</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="p">{</span><span class="s">"val_loss"</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s">"progress_bar"</span><span class="p">:</span> <span class="n">tensorboard_log</span><span class="p">}</span>
</pre></table></code></div></div><p> </p><p>학습이 끝난 후 평가 할 test step도 동일하게 작성해줍니다.<br /> 실제 추론한 결과를 리턴 받고 싶다면 test_epoch_end()의 return 값이 추가하면 됩니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_nb</span><span class="p">):</span>
    <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">slot_labels</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_convert_ids_to_labels</span><span class="p">(</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span>
    <span class="p">)</span>

    <span class="n">test_f1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_f1_score</span><span class="p">(</span><span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span><span class="p">)</span>

    <span class="n">test_step_outputs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"test_f1"</span><span class="p">:</span> <span class="n">test_f1</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">test_step_outputs</span>

<span class="k">def</span> <span class="nf">test_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="n">test_f1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s">"test_f1"</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]).</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">test_step_outputs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"test_f1"</span><span class="p">:</span> <span class="n">test_f1</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">test_step_outputs</span>
</pre></table></code></div></div><p> </p><p>모델 생성을 완료하였습니다.<br /> 최종 소스코드입니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertConfig</span><span class="p">,</span> <span class="n">BertModel</span><span class="p">,</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">seqeval.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">load_slot_labels</span>
<span class="kn">from</span> <span class="nn">dataset</span> <span class="kn">import</span> <span class="n">CorpusDataset</span>

<span class="k">class</span> <span class="nc">SpacingBertModel</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">CorpusDataset</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">slot_labels_type</span> <span class="o">=</span> <span class="p">[</span><span class="s">"UNK"</span><span class="p">,</span> <span class="s">"PAD"</span><span class="p">,</span> <span class="s">"B"</span><span class="p">,</span> <span class="s">"I"</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">bert_config</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">bert_model</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">slot_labels_type</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">bert_model</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">bert_config</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">bert_config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">slot_labels_type</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_nb</span><span class="p">):</span>

        <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">slot_labels</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_calculate_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span><span class="p">)</span>
        <span class="n">tensorboard_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s">"train_loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span><span class="s">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s">"log"</span><span class="p">:</span> <span class="n">tensorboard_logs</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_nb</span><span class="p">):</span>

        <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">slot_labels</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_calculate_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span><span class="p">)</span>
        <span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_convert_ids_to_labels</span><span class="p">(</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span>
        <span class="p">)</span>

        <span class="n">val_f1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_f1_score</span><span class="p">(</span><span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s">"val_loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s">"val_f1"</span><span class="p">:</span> <span class="n">val_f1</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]).</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">val_f1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s">"val_f1"</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]).</span><span class="n">mean</span><span class="p">()</span>

        <span class="n">tensorboard_log</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"val_loss"</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span>
            <span class="s">"val_f1"</span><span class="p">:</span> <span class="n">val_f1</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span><span class="s">"val_loss"</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s">"progress_bar"</span><span class="p">:</span> <span class="n">tensorboard_log</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_nb</span><span class="p">):</span>

        <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">slot_labels</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_convert_ids_to_labels</span><span class="p">(</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span>
        <span class="p">)</span>

        <span class="n">test_f1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_f1_score</span><span class="p">(</span><span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span><span class="p">)</span>

        <span class="n">test_step_outputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"test_f1"</span><span class="p">:</span> <span class="n">test_f1</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">test_step_outputs</span>

    <span class="k">def</span> <span class="nf">test_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">test_f1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s">"test_f1"</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]).</span><span class="n">mean</span><span class="p">()</span>

        <span class="n">test_step_outputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"test_f1"</span><span class="p">:</span> <span class="n">test_f1</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">test_step_outputs</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dataset</span><span class="p">[</span><span class="s">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">train_batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dataset</span><span class="p">[</span><span class="s">"val"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">eval_batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dataset</span><span class="p">[</span><span class="s">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">eval_batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_calculate_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">active_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">slot_labels_type</span><span class="p">))</span>
        <span class="n">active_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">active_logits</span><span class="p">,</span> <span class="n">active_labels</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">_f1_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="n">f1_score</span><span class="p">(</span><span class="n">gt_slot_labels</span><span class="p">,</span> <span class="n">pred_slot_labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_convert_ids_to_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">slot_labels</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">slot_label_ids</span> <span class="o">=</span> <span class="n">slot_labels</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">slot_label_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">label</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">slot_labels_type</span><span class="p">)}</span>
        <span class="n">slot_gt_labels</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">slot_label_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
        <span class="n">slot_pred_labels</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">slot_label_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">slot_label_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">slot_label_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">slot_label_ids</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">:</span>
                    <span class="n">slot_gt_labels</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">slot_label_map</span><span class="p">[</span><span class="n">slot_label_ids</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]])</span>
                    <span class="n">slot_pred_labels</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">slot_label_map</span><span class="p">[</span><span class="n">y_hat</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]])</span>

        <span class="k">return</span> <span class="n">slot_gt_labels</span><span class="p">,</span> <span class="n">slot_pred_labels</span>
</pre></table></code></div></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/nlp/'>nlp</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/bert/" class="post-tag no-text-decoration" >bert</a> <a href="/tags/spacing/" class="post-tag no-text-decoration" >spacing</a> <a href="/tags/%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0/" class="post-tag no-text-decoration" >띄어쓰기</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델 - 개발자&url=http://localhost:4000/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_03/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델 - 개발자&u=http://localhost:4000/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_03/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 03. 모델 - 개발자&url=http://localhost:4000/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_03/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_02/">BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 02. 데이터 전처리</a><li><a href="/posts/ch2_patterns_for_cleaner_python/">[Python Tricks]chapter2. Patterns for Cleaner Python</a><li><a href="/posts/leetcode-739/">[LeetCode]739. Daily Temperatures</a><li><a href="/posts/leetcode-3sum/">[LeetCode]3sum</a><li><a href="/posts/docstring/">[Python]Docstring</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/algorithm/">algorithm</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/bert/">bert</a> <a class="post-tag" href="/tags/spacing/">spacing</a> <a class="post-tag" href="/tags/%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0/">띄어쓰기</a> <a class="post-tag" href="/tags/docstring/">docstring</a> <a class="post-tag" href="/tags/python-tricks/">Python Tricks</a> <a class="post-tag" href="/tags/3sum/">3sum</a> <a class="post-tag" href="/tags/convention/">convention</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_01/"><div class="card-body"> <span class="timeago small" > Jan 8 <i class="unloaded">2021-01-08T00:11:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 01. 데이터 준비</h3><div class="text-muted small"><p> Pretrained BERT, PYTORCH를 이용해 한국어 띄어쓰기 모델을 만들어 보겠습니다. 한국어 데이터셋 한국어 띄어쓰기 모델을 학습하기 위해서는 띄어쓰기가 잘 되어 있는 데이터셋이 필요합니다. 세종 코퍼스, 모두의 말뭉치 처럼 오픈 데이터셋도 있고, 네이버 뉴스 같은 것을 직접 크롤링 할 수도 있습니다. 이번에는 최근에 공개된 모두의 말뭉치...</p></div></div></a></div><div class="card"> <a href="/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_02/"><div class="card-body"> <span class="timeago small" > Jan 10 <i class="unloaded">2021-01-10T00:11:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 02. 데이터 전처리</h3><div class="text-muted small"><p> 띄어쓰기 태깅 먼저 띄어쓰기에 대한 태깅 합니다. NER과 동일한 방법으로 각 토큰을 BI로 표현해보겠습니다. word 기준이 아닌 char 기준으로 태깅을 합니다. sentence = "그 외 기간은 관계자 외 출입금지입니다.".split(" ") tags = [] for word in sentence: for i in range(len(...</p></div></div></a></div><div class="card"> <a href="/posts/dictionary_default_values/"><div class="card-body"> <span class="timeago small" > Dec 16, 2020 <i class="unloaded">2020-12-16T10:11:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[python] dictionary에 default value 사용하기</h3><div class="text-muted small"><p> Python Tricks 책의 7.1 Dictionary Default Values 정리 내용입니다. 아래와 같은 dictionary가 있을때 arsenal_player_number = { 14: "auba", 10: "ozil", 35: "gabi", } 각 선수이름에 해당하는 등번호를 출력하고 싶다. def pri...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/BERT%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0_02/" class="btn btn-outline-primary"><p>BERT를 이용한 한국어 띄어쓰기 모델 만들기 - 02. 데이터 전처리</p></a> <span class="btn btn-outline-primary disabled"><p>-</p></span></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://github.com/bhchoi">choi</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/algorithm/">algorithm</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/bert/">bert</a> <a class="post-tag" href="/tags/spacing/">spacing</a> <a class="post-tag" href="/tags/%EB%9D%84%EC%96%B4%EC%93%B0%EA%B8%B0/">띄어쓰기</a> <a class="post-tag" href="/tags/docstring/">docstring</a> <a class="post-tag" href="/tags/python-tricks/">Python Tricks</a> <a class="post-tag" href="/tags/3sum/">3sum</a> <a class="post-tag" href="/tags/convention/">convention</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="http://localhost:4000{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
